{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nULVrvLmZjWr"
      },
      "outputs": [],
      "source": [
        "!pip install bertopic datasets openai datamapplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hj-VLILta6no"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"maartengr/arxiv_nlp\")[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhEFPd3Gbm3j",
        "outputId": "fd34d90f-a023-4e23-e414-bc2dff72a6eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Titles', 'Abstracts', 'Years', 'Categories'],\n",
              "    num_rows: 44949\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDxq9v63brjx"
      },
      "outputs": [],
      "source": [
        "# Extract metadata\n",
        "abstracts = list(dataset[\"Abstracts\"])\n",
        "titles = list(dataset[\"Titles\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gruYEgp1cLVQ"
      },
      "source": [
        "### A common Pipeline for Text Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAmvnUce8fk-"
      },
      "source": [
        "#### **1. Embedding Documents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFjDRIgTb9cs"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Create an embedding for each abstract\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = embedding_model.encode(abstracts, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysiBXM9e9MYs"
      },
      "outputs": [],
      "source": [
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wg0o2yqElaX"
      },
      "source": [
        "#### **2. Reducing the Dimensionality of Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orb6qQ-uC4Ye"
      },
      "outputs": [],
      "source": [
        "from umap import UMAP\n",
        "\n",
        "umap_model = UMAP(\n",
        "    n_components=5,\n",
        "    n_neighbors=15,\n",
        "    min_dist=0.0,\n",
        "    metric='cosine',\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghee_Nl-DlIu"
      },
      "outputs": [],
      "source": [
        "reduced_embeddings = umap_model.fit_transform(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4hGDhczECSV"
      },
      "outputs": [],
      "source": [
        "reduced_embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BZpmSOME-h5"
      },
      "source": [
        "#### **3. Cluster the Reduced Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5YSbltBEGus"
      },
      "outputs": [],
      "source": [
        "from hdbscan import HDBSCAN\n",
        "\n",
        "# We fit the model and extract the clusters\n",
        "hdbscan_model = HDBSCAN(\n",
        "    min_cluster_size=50, metric='euclidean', cluster_selection_method='eom'\n",
        ").fit(reduced_embeddings)\n",
        "clusters = hdbscan_model.labels_\n",
        "\n",
        "# How many clusters did we generate?\n",
        "len(set(clusters))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh1uJM6UTx4o"
      },
      "source": [
        "### Inspecting the Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpLvuiRlTVgE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Print first three documents in cluster 0\n",
        "cluster = 0\n",
        "for index in np.where(clusters==cluster)[0][:3]:\n",
        "    print(abstracts[index][:300] + \"... \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp6cM7JpasNm"
      },
      "source": [
        "#### Next, we reduce our embeddings to 2-dimensions so that we can plot them and get a rough understanding of the generated clusters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFcxDwqeUGFn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Reduce 384-dimensional embeddings to 2 dimensions for easier visualization\n",
        "reduced_embeddings = UMAP(\n",
        "    n_components=2, min_dist=0.0, metric='cosine', random_state=42\n",
        ").fit_transform(embeddings)\n",
        "\n",
        "# Create dataframe\n",
        "df = pd.DataFrame(reduced_embeddings, columns=[\"x\", \"y\"])\n",
        "df[\"title\"] = titles\n",
        "df[\"cluster\"] = [str(c) for c in clusters]\n",
        "\n",
        "# Select outliers and non-outliers (clusters)\n",
        "clusters_df = df.loc[df.cluster != \"-1\", :]\n",
        "outliers_df = df.loc[df.cluster == \"-1\", :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSY6m63rfnDp"
      },
      "source": [
        "### Static Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gI23Gbia_-f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot outliers and non-outliers seperately\n",
        "plt.scatter(outliers_df.x, outliers_df.y, alpha=0.05, s=2, c=\"grey\")\n",
        "plt.scatter(\n",
        "    clusters_df.x, clusters_df.y, c=clusters_df.cluster.astype(int),\n",
        "    alpha=0.6, s=2, cmap='tab20b'\n",
        ")\n",
        "plt.axis('off')\n",
        "plt.savefig(\"matplotlib.png\", dpi=300)  # Uncomment to save the graph as a .png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2cH5O8pgFpz"
      },
      "source": [
        "### From Text Clustering to Topic Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHWVzqaAgKo3"
      },
      "source": [
        "### BERTopic: A Modular Topic Modeling Framework\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2WjZmeuftml"
      },
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "# Train our model with our previously defined models\n",
        "topic_model = BERTopic(\n",
        "    embedding_model=embedding_model,\n",
        "    umap_model=umap_model,\n",
        "    hdbscan_model=hdbscan_model,\n",
        "    verbose=True\n",
        ").fit(abstracts, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jfQiLibghOS"
      },
      "outputs": [],
      "source": [
        "topic_model.get_topic_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CtwfJscg-fX"
      },
      "outputs": [],
      "source": [
        "topic_model.get_topic(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YKFqWaZhFTV"
      },
      "outputs": [],
      "source": [
        "topic_model.find_topics(\"topic modeling\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krbytHpyhI_y"
      },
      "outputs": [],
      "source": [
        "topic_model.get_topic(22)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ANUTDI4hLmd"
      },
      "outputs": [],
      "source": [
        "topic_model.topics_[titles.index('BERTopic: Neural topic modeling with a class-based TF-IDF procedure')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiQZpeMnhUwu"
      },
      "source": [
        "#### It is! We expected it might be because there are non-LDA specific words in the topic describtion such as \"clustering\" and \"topic\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-y_Lxk6hc6b"
      },
      "source": [
        "### Visualizations\n",
        "### Visualize Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xlEHDF1hOo_"
      },
      "outputs": [],
      "source": [
        "# Visualize topics and documents\n",
        "fig = topic_model.visualize_documents(\n",
        "    titles,\n",
        "    reduced_embeddings=reduced_embeddings,\n",
        "    width=1200,\n",
        "    hide_annotations=True\n",
        ")\n",
        "\n",
        "# Update fonts of legend for easier visualization\n",
        "fig.update_layout(font=dict(size=16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIiBA04WhkKL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}