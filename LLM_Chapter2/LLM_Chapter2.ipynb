{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Note** We need GPU for run this notebook, so in Google Colab, go to Runtime > Change runtime type > Hardware accelerator > GPU > GPU type > T4."
      ],
      "metadata": {
        "id": "lqMLOAlkwxeI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jb99T7KwLXdO"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade transformers==4.41.2 sentence-transformers==3.0.1 gensim==4.3.2 scikit-learn==1.5.0 accelerate==0.31.0 peft==0.11.1 scipy==1.10.1 numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkVvxWSfWl-o"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=False,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doosfgn-W5By"
      },
      "outputs": [],
      "source": [
        "prompt = \"Write an email apologizing to Sarah for the tragic gardening mishap. Explain how it happened.<|assistant|>\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYJ8YHHHY7Mx"
      },
      "outputs": [],
      "source": [
        "# Tokenize the input prompt\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEC_XVcaY-Jd"
      },
      "outputs": [],
      "source": [
        "# Generate the text\n",
        "generation_output = model.generate(\n",
        "  input_ids=input_ids,\n",
        "  max_new_tokens=20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rOGzY21ZDEr",
        "outputId": "ad63de3b-a8f3-4aba-92e9-22dc02708304"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Write an email apologizing to Sarah for the tragic gardening mishap. Explain how it happened.<|assistant|> Subject: Heartfelt Apologies for the Gardening Mishap\n",
            "\n",
            "\n",
            "Dear\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(generation_output[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvB9FjOVZJo4",
        "outputId": "9bfdc729-f08b-472f-e88d-1ffdc690fba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[14350,   385,  4876, 27746,  5281,   304, 19235,   363,   278, 25305,\n",
            "           293, 16423,   292,   286,   728,   481, 29889, 12027,  7420,   920,\n",
            "           372,  9559, 29889, 32001]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wSqg9AjZtNl",
        "outputId": "caee2041-ce42-4d82-b278-90d49f98b177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Write an email apologizing to Sarah for the tragic gardening mishap. Explain how it happened.<|assistant|>\n"
          ]
        }
      ],
      "source": [
        "for id in input_ids:\n",
        "  print(tokenizer.decode(id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sbl-7_MiZ00X",
        "outputId": "8461b95a-148a-4ebf-d470-5df812894c12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[14350,   385,  4876, 27746,  5281,   304, 19235,   363,   278, 25305,\n",
            "           293, 16423,   292,   286,   728,   481, 29889, 12027,  7420,   920,\n",
            "           372,  9559, 29889, 32001,  3323,   622, 29901, 17778, 29888,  2152,\n",
            "          6225, 11763,   363,   278, 19906,   292,   341,   728,   481,    13,\n",
            "            13,    13, 29928,   799]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(generation_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRWGFvYXZ_RD",
        "outputId": "a67e571e-2434-4ce0-e016-32a45f17eb16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Write\n",
            "ish\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(14350))\n",
        "print(tokenizer.decode(728))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzDetrGOeQs7"
      },
      "outputs": [],
      "source": [
        "### Comparing Trained LLM Tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoLjKlEIaL_t"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX-epi59dm8n"
      },
      "outputs": [],
      "source": [
        "colors_list = [\n",
        "    '102;194;165', '252;141;98', '141;160;203',\n",
        "    '231;138;195', '166;216;84', '255;217;47'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHwdYVZtdpLU"
      },
      "outputs": [],
      "source": [
        "def show_tokens(sentence, tokenizer_name):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "    token_ids = tokenizer(sentence).input_ids\n",
        "    for idx, t in enumerate(token_ids):\n",
        "        print(\n",
        "            f'\\x1b[0;30;48;2;{colors_list[idx % len(colors_list)]}m' +\n",
        "            tokenizer.decode(t) +\n",
        "            '\\x1b[0m',\n",
        "            end=' '\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kh9_-c_beGnc"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "English and CAPITALIZATION\n",
        "ðŸŽµ é¸Ÿ\n",
        "show_tokens False None elif == >= else: two tabs:\"    \" Three tabs: \"       \"\n",
        "12.0*50=600\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH1J00SNeMUI"
      },
      "outputs": [],
      "source": [
        "show_tokens(text, \"microsoft/Phi-3-mini-4k-instruct\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z47aubfpey58"
      },
      "outputs": [],
      "source": [
        "show_tokens(text, \"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQd-A_QogbdT"
      },
      "outputs": [],
      "source": [
        "show_tokens(text, \"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePHL1-ktgqEq"
      },
      "outputs": [],
      "source": [
        "show_tokens(text, \"gpt2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MWCSJozg-yZ"
      },
      "source": [
        "## Contextualized Word Embeddings From a Language Model (Like BERT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zX57DZfLhC9s"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_jPlXg6hZiW"
      },
      "outputs": [],
      "source": [
        "# Load a Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
        "\n",
        "# Load a Language Model\n",
        "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-xsmall\")\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = tokenizer(\"Hello World\", return_tensors = \"pt\")\n",
        "\n",
        "output = model(**tokens)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px3u_vItiIzo",
        "outputId": "7962c5a0-b197-4aa8-8cf7-d4ced30a591f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 384])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbEY4p7Wicck",
        "outputId": "c2060cbb-0ba1-49f3-ed9c-27f4b18c0b0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS]\n",
            "Hello\n",
            " World\n",
            "[SEP]\n"
          ]
        }
      ],
      "source": [
        "for token in tokens[\"input_ids\"][0]:\n",
        "  print(tokenizer.decode(token))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogxuwr72j8EP",
        "outputId": "0d80d7fe-1412-44eb-e5ec-de09d72db222"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[    1, 31414,   623,     2]]), 'token_type_ids': tensor([[0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1]])}\n"
          ]
        }
      ],
      "source": [
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71DPKZJuipDw"
      },
      "outputs": [],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rJnQ3wHelGJZ"
      },
      "outputs": [],
      "source": [
        "# e.g., embeddings for the first token\n",
        "token_embeddings = output[0]  # Shape: (1, 4, 384)\n",
        "# Access shape to get token embeddings for the specific tokens\n",
        "for i in range(token_embeddings.shape[1]):\n",
        "    embedding = token_embeddings[0, i]  # shape will be (384,)\n",
        "    print(f\"Embedding for token {i}: {embedding.shape}\")  # (384,)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX3rHZiLZc24"
      },
      "source": [
        "## **Text Embeddings (For Sentences and Whole Documents)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48nyOovbYWY8"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjz3cwCbZxiS"
      },
      "outputs": [],
      "source": [
        "# Load Model\n",
        "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "\n",
        "# Convert text to text embeddings\n",
        "vector = model.encode(\"Best movie ever!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-gLcj2PaJyF",
        "outputId": "72c03b7d-1a35-4ea8-8c4a-013d67be4c78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(768,)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nFHB292agb_"
      },
      "source": [
        "**Word Embeddings Beyond LLMs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OwWXfA_YbsQx"
      },
      "outputs": [],
      "source": [
        "# !pip install gensim sentence-transformers transformers scikit-learn accelerate peft\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhtdoliaaVUW"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "j94bjqAea1lL",
        "outputId": "b8756668-eb00-4fa2-c817-2b8439a60d20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ],
      "source": [
        "model = api.load(\"glove-wiki-gigaword-50\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5sF0zS5cMHM"
      },
      "outputs": [],
      "source": [
        "model.most_similar([model['king']], topn=11)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}